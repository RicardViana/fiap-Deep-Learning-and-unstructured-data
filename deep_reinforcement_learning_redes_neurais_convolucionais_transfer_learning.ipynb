{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d6ca84",
   "metadata": {},
   "source": [
    "#### **Deep & Reinforcement Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580d69f",
   "metadata": {},
   "source": [
    "#### **Observa√ß√µes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d240e1",
   "metadata": {},
   "source": [
    "##### **Classificando c√£es üêï e gatos üêà**\n",
    "\n",
    "Voc√™ j√° imaginou criar uma rede neural para classificar imagens? As redes neurais convolucionais (CNNs) s√£o amplamente utilizadas em uma variedade de aplica√ß√µes de vis√£o computacional e processamento de imagens devido √† sua capacidade de aprender representa√ß√µes hier√°rquicas de dados.\n",
    "\n",
    "Na aula de hoje vamos criar uma rede neural para classificar c√£es e gatos. Sabemos que para os olhos humanos √© f√°cil a identifica√ß√£o dos animais por meio de algumas diferen√ßas entre ambos, tal como gatos possuem os olhos mais puxadinhos, orelhinhas mais pontudas e entre outras caracter√≠sticas. Mas tamb√©m sabemos que temos c√£es que podem ter caracter√≠sticas semelhantes ao gato, tal como a orelhinha pontuda, cauda longa, e entre outras caracter√≠sticas. Ser√° que a rede neural consegue distinguir os animais? Vamos codar e descobrir juntos!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e88704",
   "metadata": {},
   "source": [
    "##### Classificando not√≠cias com Redes Neurais Recorrentes üì∞\n",
    "Imagine que temos o desafio de organizar diversos tipos de not√≠cias por assuntos, como voc√™ faria? Basicamente podemos classificar uma not√≠cia dado algum contexto, por exemplo:\n",
    "\n",
    "\"Pela quarta rodada do Campeonato Italiano, a Roma n√£o tomou conhecimento do Empoli neste domingo e venceu pela primeira vez na competi√ß√£o.\"\n",
    "\n",
    "Com base nesse contexto, poderiamos classificar essa not√≠cia como do tipo \"Esportes\", certo? E por que sabemos disso? Bem, podemos observar algumas palavrinhas chaves tal como \"campeonato\" e \"competi√ß√£o\".\n",
    "\n",
    "Nessa aula, temos o desafio de ensinar uma rede neural recorrente realizar esse tipo de trabalho! Classificar not√≠cias com base em textos.\n",
    "\n",
    "Como bem j√° sabemos, as redes neurais recorrentes aprende com ela mesma (assim como n√≥s humanos aprendemos com nossos erros). Basicamente, esse tipo de arquitetura aprende n√£o s√≥ com os dados de entrada mas tamb√©m com as pr√≥prias sa√≠das da rede (muito parecido com um looping de aprendizado, por isso chamamos de redes recorrentes). Como nesse cen√°rio precisamos de uma sequ√™ncia de palavras para fazer sentido ao contexto, as RNNs podem ser uma boa alternativa! Vamos codar? üòÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831837de",
   "metadata": {},
   "source": [
    "##### **Como criar ambientes para evitar conflito:**\n",
    "https://github.com/RicardViana/fiap-data-viz-and-production-models/blob/main/Roteiro%20para%20cria%C3%A7%C3%A3o%20de%20ambiente.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59115f",
   "metadata": {},
   "source": [
    "#### **Conte√∫do - Bases e Notebook da aula**\n",
    "\n",
    "Github:  \n",
    "https://github.com/FIAP/Pos_Tech_DTAT/tree/DeepLearning\n",
    "\n",
    "ou\n",
    "\n",
    "https://github.com/FIAP/Pos_Tech_DTAT/tree/main\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770d68e",
   "metadata": {},
   "source": [
    "#### **Importa√ß√£o de bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar biblioteca completa\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import gdown\n",
    "import config\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Importar algo especifico de uma biblioteca\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics as skm\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import Precision\n",
    "from tqdm.keras import TqdmCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout, Conv2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pathlib import Path\n",
    "from distutils.file_util import copy_file\n",
    "from keras.layers import Input\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import STOPWORDS\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from keras.src.legacy.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, SimpleRNN, Bidirectional, MaxPooling1D, GlobalMaxPool1D, LSTM, GRU\n",
    "from keras.regularizers import L1L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e672ffbc",
   "metadata": {},
   "source": [
    "#### **Fun√ß√µes (def)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8604f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_animal(filepath):\n",
    "\n",
    "    # Declaramos as vari√°veis que ser√£o criadas ao longo do c√≥digo\n",
    "    global model\n",
    "    global animal_names\n",
    "    global image_size\n",
    "\n",
    "    # L√≥gica robusta para ler caminhos com acentos\n",
    "    img_array = np.fromfile(str(filepath), np.uint8)\n",
    "    image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Erro: N√£o foi poss√≠vel carregar a imagem.\")\n",
    "        return\n",
    "\n",
    "    # Processamento\n",
    "    img = cv2.resize(image, (image_size, image_size)).astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Predi√ß√£o\n",
    "    pred = model.predict(img, verbose=0)\n",
    "    classes = np.argmax(pred, axis=1)\n",
    "\n",
    "    # Output\n",
    "    print(f\"Previs√£o: {animal_names[classes[0]]}\")\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ff418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_animal_transfer_learning(filepath):\n",
    "\n",
    "    # Declaramos as vari√°veis que ser√£o criadas ao longo do c√≥digo\n",
    "    global model\n",
    "    global animal_names\n",
    "\n",
    "    # L√≥gica robusta para ler caminhos com acentos\n",
    "    img_array = np.fromfile(str(filepath), np.uint8)\n",
    "    image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Erro: N√£o foi poss√≠vel carregar a imagem.\")\n",
    "        return\n",
    "\n",
    "    # Processamento\n",
    "    img = cv2.resize(image, (224, 224)).astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Predi√ß√£o\n",
    "    pred = model.predict(img, verbose=0)\n",
    "    classes = np.argmax(pred, axis=1)\n",
    "\n",
    "    # Output\n",
    "    print(f\"Previs√£o: {animal_names[classes[0]]}\")\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a6a55",
   "metadata": {},
   "source": [
    "#### **Aula 2 - Redes convolucionais**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0bcbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em vez de montar o drive, lemos o caminho do nosso arquivo de configura√ß√£o\n",
    "caminho_da_pasta = config.DATA_PATH\n",
    "pasta_imagens = Path(caminho_da_pasta)\n",
    "\n",
    "# Listando todas as imagens do diret√≥rio (o seu c√≥digo original)\n",
    "filepaths = list(pasta_imagens.glob(r'**/*.jpg'))\n",
    "\n",
    "# Verifica√ß√£o para garantir que os arquivos foram carregados\n",
    "if filepaths:\n",
    "    print(f\"Sucesso! Foram encontradas {len(filepaths)} imagens.\")\n",
    "    print(f\"Primeira imagem: {filepaths[0]}\")\n",
    "else:\n",
    "    print(\"Erro: Nenhuma imagem encontrada. Verifique o caminho no seu arquivo config.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb4c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando r√≥tulos e listas de imagens para armazenar os dados\n",
    "labels = [] #armazenando as vari√°veis target\n",
    "images = [] #armazenando imagens\n",
    "\n",
    "# Definindo o tamanho da dimens√£o da imagem\n",
    "image_size = 64\n",
    "\n",
    "# Um loop for para definir as vari√°veis x e y para os modelos\n",
    "for filepath in filepaths:\n",
    "\n",
    "    try:\n",
    "        \n",
    "        # Tratar caminho com espa√ßo e acento\n",
    "        img_array = np.fromfile(str(filepath), np.uint8)\n",
    "\n",
    "        # Obtem a imagem do caminho com cv2\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Verifica√ß√£o de seguran√ßa\n",
    "        if img is None:\n",
    "            print(f\"‚ö†Ô∏è Arquivo ignorado (n√£o √© uma imagem v√°lida): {filepath}\")\n",
    "            continue\n",
    "            \n",
    "        # Divide o nome do caminho para extrair o cabe√ßalho do caminho com split\n",
    "        head = os.path.split(filepath)\n",
    "\n",
    "        # Divide o cabe√ßalho do caminho anterior para extrair o nome do animal\n",
    "        animal = os.path.split(head[0])\n",
    "\n",
    "        # Armazena o nome do animal na lista de labels\n",
    "        labels.append(animal[1])\n",
    "        \n",
    "        # Redimensiona a imagem e normalize o intervalo de pixels para ficar entre 0 e 1 (padroniza√ß√£o)\n",
    "        # Utilizando float32 para criar uma precis√£o limitada (menor demanda de mem√≥ria em compara√ß√£o com tipos de ponto flutuante de maior precis√£o: float64)\n",
    "        img = cv2.resize(img, (image_size, image_size)).astype('float32') / 255.0\n",
    "\n",
    "        # Adiciona a imagem na lista de imagens\n",
    "        images.append(img)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro cr√≠tico ao processar {filepath}: {e}\")\n",
    "\n",
    "# Converte a imagem em lista de array\n",
    "images = np.array(images)\n",
    "\n",
    "# Converte as labels para lista de array\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta o shape da imagem\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2994ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar a lista de array\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2616c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar a lista de array\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir o data frame\n",
    "\n",
    "'''\n",
    "\n",
    "Com as imagens e rotulos j√° definidos, vamos construir um dataframe com o nome do caminho e o r√≥tulo da imagem.\n",
    "\n",
    "'''\n",
    "\n",
    "# Salvando a lista de caminhos de arquivo\n",
    "pd_filepaths = pd.Series(filepaths, name='Filepath').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08651036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando a lista de caminhos de arquivo\n",
    "pd_filepaths = pd.Series(filepaths, name='Filepath').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fcd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o camiho das imagens\n",
    "print(pd_filepaths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e52859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os r√≥tulos das imagens\n",
    "print(labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cdb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando a label\n",
    "pd_labels = pd.Series(labels, name='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ea400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando the filepaths and labels\n",
    "df = pd.concat([pd_filepaths, pd_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec36df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultando o data frame com o head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845503c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultando o data frame com o head\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embaralhando o dataframe\n",
    "\n",
    "'''\n",
    "\n",
    "Como dados est√£o em ordem das classes, isso pode ser um problema para o modelo, ent√£o vamos utilizar o sample para embaralhar o dataframe:\n",
    "\n",
    "'''\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee123555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultando o data frame com o head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f6e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma c√≥pia do dataframe com apenas uma imagem de cada animal\n",
    "# Subset est√° procurando por duplicatas apenas na coluna chamada 'Label' e removendo todas as duplicatas encontradas.\n",
    "df_singles = df.copy().drop_duplicates(subset=('Label')).reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348299c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer uma contagem\n",
    "len(df_singles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f255cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o n√∫mero de classes\n",
    "num_classes = df_singles.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar o numero de classes\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339689ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Agora que temos as classes mapeadas na vari√°vel num_classes, vamos visualizar duas amostras de imagens dentro do dataset:\n",
    "\n",
    "'''\n",
    "\n",
    "# Configura o n√∫mero de linhas e colunas para visualizar os dados no plot\n",
    "ROW = 1\n",
    "COLUMN = 2\n",
    "\n",
    "# Dimens√µes das imagens\n",
    "plt.figure(figsize=(12, 9))\n",
    "#Loop para cada animal\n",
    "for i in range(num_classes):\n",
    "    # Defina uma vari√°vel de imagem local para i imagem no dataframe de singles\n",
    "    image = df_singles.Filepath[i]\n",
    "    # Define a posi√ß√£o da imagem a ser plotada\n",
    "    plt.subplot(ROW, COLUMN, i+1)\n",
    "    # Mostra a imagem\n",
    "    plt.imshow(plt.imread(image))\n",
    "    # Adiciona o r√≥tulo do bichinho que corresponde √† imagem\n",
    "    plt.title('{}'.format(df_singles.Label[i]))\n",
    "    # Desliga o eixo de plotagem\n",
    "    plt.axis('off')\n",
    "    # Fa√ßa com que o preenchimento ao redor das imagens seja m√≠nimo\n",
    "    plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar em treino e teste a base de dados\n",
    "\n",
    "'''\n",
    "\n",
    "Agora com as imagens e classes organizadas, podemos aplicar o train_test_split para separar as bases de treinamento e teste: \n",
    "\n",
    "'''\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images,labels, test_size=0.2, stratify=labels, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando a dimens√£o dos dados --> x_train\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b82bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando a dimens√£o dos dados --> x_test\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70596fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "As imagens s√£o basicamente uma matriz de pixels e para colocar as imagens dentro da arquitetura das redes convolucionais, √© preciso \"achatar\" essas matrizes multidimensionais em vetores unidimensionais. \n",
    "Uma das camadas da rede, a Flatten(), √© uma das partes da rede que achata os dados antes de entrar nas camadas densas.\n",
    "\n",
    "'''\n",
    "\n",
    "# Achatar os dados de teste e treinamento\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], x_train.shape[1]* x_train.shape[2]* x_train.shape[3])\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2] * x_test.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc7f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a transforma√ß√£o\n",
    "x_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Como pr√≥ximo passo, vamos converter as classes de texto em bin√°rias. Para esse procedimento, vamos utilizar o m√©todo LabelEncoder().\n",
    "\n",
    "'''\n",
    "\n",
    "# Converter Strings em Num√©ricos\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Converte um vetor de classe (inteiros) em uma matriz de classe categ√≥rica.\n",
    "y_train_tf = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_tf = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a236e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Vamos configurar agora como pr√≥ximo passo o ModelCheckpoint para usar os melhores pesos para este modelo. \n",
    "Um dos benef√≠cios do ModelCheckpoint √© salvar uma c√≥pia do modelo em disco em intervalos regulares (como ap√≥s cada √©poca de processamento) para que voc√™ possa retomar o treinamento \n",
    "a partir do ponto em que parou, minimizando perdas de tempo e recursos computacionais.\n",
    "\n",
    "'''\n",
    "\n",
    "# Defina um objeto ModelCheckpoint para usar os melhores pesos para este modelo\n",
    "#checkpointer = ModelCheckpoint(filepath=\"weights.best.keras\", verbose=0, save_best_only=True) --> Modelo aula\n",
    "\n",
    "# Definimos o nome do ficheiro\n",
    "nome_arquivo = \"weights.best.keras\"\n",
    "\n",
    "# Criamos o checkpointer\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=nome_arquivo,\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,               \n",
    "    save_best_only=True,\n",
    "    mode='max'               \n",
    ")\n",
    "\n",
    "print(f\"‚úÖ O modelo ser√° monitorizado e salvo em: {os.path.abspath(nome_arquivo)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf91e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Como pr√≥ximo passo, vamos definir a entrada da rede e armazenar na vari√°vel\n",
    "\n",
    "input_shape e em seguida configurar a learning rate e a queda do peso do otimizador com **weight_decay**.\n",
    "\n",
    "O argumento weight_decay √© usado para aplicar regulariza√ß√£o L2 (tamb√©m conhecida como regulariza√ß√£o de peso) √†s camadas densas (fully connected) de uma rede neural durante o treinamento. \n",
    "A regulariza√ß√£o L2 funciona adicionando um termo √† fun√ß√£o de perda durante o treinamento que penaliza os pesos maiores.\n",
    "\n",
    "'''\n",
    "\n",
    "# Define a forma de entrada das imagens passadas pelo modelo\n",
    "input_shape = (image_size, image_size, 3)\n",
    "\n",
    "# Defina a taxa de aprendizado e a queda de peso para o otimizador usar\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Parametro usado na aula 3 referente a transfer√™ncia de aprendizagem\n",
    "# weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar a rede neural convolucional\n",
    "\n",
    "# Defindo uma semente aleat√≥ria para utilizar sempre os mesmos dados durante nossos testes\n",
    "tf.random.set_seed(44)\n",
    "\n",
    "# Abrindo a sequencia do modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Camada de entrada expl√≠cita\n",
    "model.add(Input(shape=input_shape))\n",
    "\n",
    "# 1 camada convolucional com 128 neur√¥nios | filtro utilizando uma matriz 3x3 sendo movimentado por um stride de 2\n",
    "# padding ativado (sem bordas de zeros) | fun√ß√£o de ativa√ß√£o ReLU | regulariza√ß√£o L2 ativada\n",
    "model.add(Conv2D(128,\n",
    "                 kernel_size=(3, 3),\n",
    "                 strides=(2, 2),\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "\n",
    "# Camada de MaxPolling ativada, com uma matriz 2x2. Padding ativado\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
    "\n",
    "# Regulariza√ß√£o de dropout ativada\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 2 camada convolucional com 92 neur√¥nios | filtro utilizando uma matriz 3x3 sendo movimentado por um stride de 2\n",
    "# padding ativado (sem bordas de zeros) | fun√ß√£o de ativa√ß√£o ReLU | regulariza√ß√£o L2 ativada\n",
    "model.add(Conv2D(92,\n",
    "                 kernel_size=(3, 3),\n",
    "                 strides=(2, 2),\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "\n",
    "# Camada de MaxPolling ativada, com uma matriz 2x2. Padding ativado\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
    "\n",
    "# Regulariza√ß√£o de dropout ativada\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Camada que achata dos dados da imagem\n",
    "model.add(Flatten())\n",
    "\n",
    "# Camada Dense da rede neural convolucional + fun√ß√£o de ativa√ß√£o ReLU\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Camada de sa√≠da da rede, utilizando a fun√ß√£o de ativa√ß√£o softmax para criar a probabilidade de pertencimento das classes\n",
    "model.add(Dense(y_train_tf.shape[1], activation='softmax'))\n",
    "\n",
    "# Visualizar resumo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbcb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Vamos configurar uma t√©cnica de valida√ß√£o do modelo para evitar que as √©pocas de processamento n√£o executem o modelo sem ter melhoras significativas, o early stopping. \n",
    "Essa t√©cnica monitora a perda no conjunto de valida√ß√£o e interrompe o treinamento se a perda n√£o diminuir significativamente por um n√∫mero especificado de √©pocas (10 no exemplo)\n",
    "ap√≥s uma pequena melhoria (m√≠nimo delta de 1e-5). Essa √© uma t√©cnica √∫til para evitar o overfitting e economizar tempo de treinamento. \n",
    "Podemos dizer que essa t√©cnica ajuda o modelo a n√£o ficar \"estagnado\", ou seja, se encontra em estado estacion√°rio\n",
    "\n",
    "Al√©m da configura√ß√£o do early stopping, vamos configurar a fun√ß√£o de custo com o Adam. A fun√ß√£o de custo tem o papel de ajustar os pesos de uma rede neural durante o treinamento. \n",
    "O Adam tamb√©m utiliza um termo de momentum para acelerar o processo de aprendizado. \n",
    "O momentum ajuda o algoritmo a superar regi√µes planas ou m√≠nimos locais rasos, permitindo que ele \"ganhe velocidade\" na dire√ß√£o do m√≠nimo global. \n",
    "O otimizador Adam requer menos configura√ß√£o de hiperpar√¢metro da taxa de aprendizagem, ent√£o um valor padr√£o n = 0,001 pode ser uma boa op√ß√£o!\n",
    "\n",
    "Lembrando que a taxa de aprendizagem (learning rate) √© respons√°vel por controlar o tamanho dos ‚Äúpassos‚Äù das intera√ß√µes para encontrar um melhor m√≠nimo local (menor erro). \n",
    "Uma taxa de aprendizagem baixa pode ser mais precisa, por√©m pode demorar para encontrar o m√≠nimo local. Uma taxa de aprendizado alta pode deixar passar o melhor m√≠nimo local.\n",
    "\n",
    "'''\n",
    "\n",
    "# Monitor para interromper o modelo antecipadamente quando a melhoria da perda de valida√ß√£o for m√≠nima\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=10, verbose=1, mode='auto') #Aqui utilizando early stopping\n",
    "\n",
    "# Compilando o modelo e aplica√ß√£o a fun√ß√£o de custo Adam (utilizando a learning rate que configuramos anteriormente)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate), metrics=['accuracy'])\n",
    "\n",
    "# Salve os dados do modelo em um arquivo keras\n",
    "model.save('./cat_dog.keras')\n",
    "\n",
    "print(f\"‚úÖ O modelo ser√° monitorizado e salvo em: {os.path.abspath('cat_dog.keras')}\")\n",
    "\n",
    "# Resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f085c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "history = model.fit(x_train,y_train_tf, validation_split=0.25, callbacks=[monitor,checkpointer],verbose=1,epochs=45, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Valida√ß√£o do modelo\n",
    "\n",
    "Existem duas m√©tricas importantes que devemos analisar ap√≥s executar a rede neural, o valor de erro observado e o valor de acur√°cia por √©pocas de processamento. \n",
    "Uma boa pr√°tica √© analisarmos com gr√°ficos de linhas para identificarmos as tend√™ncias da performance da rede.\n",
    "\n",
    "'''\n",
    "\n",
    "# Valida√ß√£o o erro por √©pocas\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valida√ß√£o da acur√°cia por √©pocas\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c431936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Agora vamos armazenar as predi√ß√µes da base de teste na vari√°vel de predi√ß√£o cnn_pred_cat_dog\n",
    "\n",
    "'''\n",
    "\n",
    "# Armazena as predica√ß√µes do modelo dos dados de teste em uma vari√°vel\n",
    "cnn_pred_cat_dog = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dcd830",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Vamos utilizar o argmax do numpy para encontrar a classe com a maior probabilidade prevista para cada amostra. (Lembrando que utilizamos a softmax)\n",
    "\n",
    "'''\n",
    "\n",
    "# Define o √≠ndice do valor m√°ximo do modelo de previs√£o para uma vari√°vel\n",
    "# O valor m√°ximo indica o caractere de previs√£o do modelo que a imagem representa\n",
    "cnn_pred_cat_dog = np.argmax(cnn_pred_cat_dog,axis=1)\n",
    "\n",
    "# Define uma vari√°vel para armazenar o r√≥tulo que representa o resultado verdadeiro\n",
    "y_true = np.argmax(y_test_tf,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288716a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Vamos organizar os nomes dos animais (gatinhos e cachorrinhos) em uma vari√°vel, a fim de criar uma lista √∫nica de nomes de animais, ordenados alfabeticamente. \n",
    "Vamos tamb√©m remover duplicatas e ordenar os nomes em ordem alfab√©tica, resultando em uma lista √∫nica, limpa e ordenada de nomes de animais.\n",
    "\n",
    "'''\n",
    "\n",
    "# Cria um array de nomes de caracteres igual ao array de labels\n",
    "animal_names = labels\n",
    "\n",
    "# Reduza os nomes dos animais para apenas valores dict √∫nicos\n",
    "animal_names = list(dict.fromkeys(animal_names))\n",
    "\n",
    "# Ordena os caracteres em ordem alfab√©tica, qual √© a ordem em que os dados s√£o alimentados\n",
    "animal_names = sorted(animal_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Importante analisar o escopo das classes, ent√£o vamos utilizar o classification_report e analisar os resultados por escopo das vari√°veis targets.\n",
    "\n",
    "'''\n",
    "\n",
    "# Criando a matriz de confus√£o\n",
    "cnn_cm_cat_dog = skm.confusion_matrix(y_true, cnn_pred_cat_dog)\n",
    "\n",
    "# Definindo a acur√°cia\n",
    "cnn_accuracy_cat_dog = skm.accuracy_score(y_true, cnn_pred_cat_dog)\n",
    "\n",
    "# Print do classification report\n",
    "print(classification_report(y_true, cnn_pred_cat_dog, target_names=animal_names))\n",
    "\n",
    "# Print da acur√°cia\n",
    "print(\"Accuracy score: {}\".format(cnn_accuracy_cat_dog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8627f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = r\"C:\\Users\\ricar\\OneDrive\\Cursos\\P√≥s Gradua√ß√£o\\Data Analytics - FIAP\\07 - Fase 5 - Deep Learning and Unstructured Data\\02 - Deep & Reinforcement Learning\\Outros\\imagens_teste\\cat.202.jpg\"\n",
    "guess_animal(caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892fac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = r\"C:\\Users\\ricar\\OneDrive\\Cursos\\P√≥s Gradua√ß√£o\\Data Analytics - FIAP\\07 - Fase 5 - Deep Learning and Unstructured Data\\02 - Deep & Reinforcement Learning\\Outros\\imagens_teste\\cat.475.jpg\"\n",
    "guess_animal(caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48556b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = r\"C:\\Users\\ricar\\OneDrive\\Cursos\\P√≥s Gradua√ß√£o\\Data Analytics - FIAP\\07 - Fase 5 - Deep Learning and Unstructured Data\\02 - Deep & Reinforcement Learning\\Outros\\imagens_teste\\dog.30.jpg\"\n",
    "guess_animal(caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = r\"C:\\Users\\ricar\\OneDrive\\Cursos\\P√≥s Gradua√ß√£o\\Data Analytics - FIAP\\07 - Fase 5 - Deep Learning and Unstructured Data\\02 - Deep & Reinforcement Learning\\Outros\\imagens_teste\\dog.238.jpg\"\n",
    "guess_animal(caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = r\"C:\\Users\\ricar\\OneDrive\\Cursos\\P√≥s Gradua√ß√£o\\Data Analytics - FIAP\\07 - Fase 5 - Deep Learning and Unstructured Data\\02 - Deep & Reinforcement Learning\\Outros\\imagens_teste\\dog.jpg\"\n",
    "guess_animal(caminho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec4ee6",
   "metadata": {},
   "source": [
    "#### **Aula 3 - Transfer√™ncia de aprendizagem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Criando uma rede neural transfer learning com MobileNetV2 \n",
    "\n",
    "Problema identificado nas redes neurais CNN constru√≠das do zero:\n",
    "\n",
    "Perceba aqui que a rede neural CNN para classificar c√£es e gatos n√£o foi t√£o eficaz assim. \n",
    "Dentro de um dos problemas de deep learning, temos a quest√£o de overfitting que pode ser ocasionada por v√°rios cen√°rios.\n",
    "\n",
    "Perceba que ao analisar o gr√°fico da nossa rede neural convolucional, at√© a 10¬™ √©poca de processamento, os conjuntos de treinamento e valida√ß√£o \n",
    "pareciam andar juntos em quest√£o de performance, mas esse comportamento foi se perdendo ao longo do processamento da rede, nos resultado em 71% de \n",
    "acur√°cia para valida√ß√£o e 84% para treinamento.\n",
    "\n",
    "\n",
    "Existem muitas formas de reduzir o overfitting em deep learning, tal como t√©cnicas de regulariza√ß√£o, batch normalization e tamb√©m aumentar o tamanho da base \n",
    "de treinamento dos dados. Parece muito, mas 1000 imagens podem ser muito pouco para ensinar uma rede neural a aprender os detalhes e particularidades de \n",
    "caracter√≠sticas de imagens. Se utilizarmos por exemplo uma rede neural que j√° foi treinada com milhares de imagens de amostra, com certeza seu desempenho \n",
    "pode melhorar muito. Dentro do treinamento de redes neurais convolucionais, no in√≠cio da extra√ß√£o de caracter√≠sticas de imagens, alguns passos podem se tornar\n",
    "‚Äúpadr√£o‚Äù em qualquer tipo de imagem, tal como identifica√ß√£o de bordas por exemplo. As camadas iniciais e centrais s√£o aplicadas √† aprendizagem por transfer√™ncia, e as \n",
    "√∫ltimas camadas s√£o apenas recicladas. A rede faz uso dos dados rotulados da tarefa na qual foi treinado.Se tivermos uma rede neural transfer learning que \n",
    "j√° sabe identificar e muito bem esse tipo de comportamento, podemos ganhar performance e dar um upgrade no nosso modelo e conseguir classificar outros \n",
    "tipos de imagens dado o aprendizado obtido.\n",
    "\n",
    "\n",
    "Solu√ß√£o prospota:\n",
    "\n",
    "Para dar um upgrade em nossa rede neural, criar uma rede transfer learning utilizando a biblioteca do Keras, a MobileNetV2!\n",
    "MobileNetV2 √© uma arquitetura de rede neural convolucional eficiente que utiliza blocos de gargalo, convolu√ß√µes separ√°veis, camadas residuais e outras t√©cnicas para\n",
    "equilibrar o desempenho e a efici√™ncia de recursos.\n",
    "\n",
    "Vamos iniciar importando as bibliotecas necess√°rias do keras para criar a transfer learning e em seguida j√° come√ßar a constru√ß√£o do modelo. \n",
    "Vamos chamar a classe MobileNetV2 e configurar dois hiperpar√¢metros muito importantes: weights e include_top.\n",
    "\n",
    "* weights s√£o os pesos da rede que foram treinados pela MobileNetV2.\n",
    "* include_top exclui a camada final de classifica√ß√£o da rede, ou seja, ela utiliza todo o treinamento aprendido pela MobileNetV2 no conjunto de imagens da ImageNet, \n",
    "mas na hora de criar os r√≥tulos, conseguimos criar de forma personalizada de acordo com a nossa rede neural tratada no assunto desejado.\n",
    "\n",
    "E porque essa rede \"pr√©-treinada\" funciona?\n",
    "\n",
    "Bem, porque alguns passos comuns aprendidos em redes neurais como por exemplo:\n",
    "\n",
    "* Convolu√ß√µes de Bordas e Texturas\n",
    "* Caracter√≠sticas Complexas de Objetos\n",
    "* Hierarquia de Caracter√≠sticas\n",
    "* Representa√ß√µes de Alto N√≠vel\n",
    "* Redu√ß√£o da Dimensionalidade\n",
    "\n",
    "Uma das principais caracter√≠sticas da MobileNetV2 √© sua capacidade de generaliza√ß√£o. \n",
    "Como foi treinada em um conjunto de dados diversificado e desafiador, ela pode reconhecer uma ampla variedade de objetos e padr√µes em imagens de entrada.\n",
    "\n",
    "'''\n",
    "\n",
    "# Carregue o modelo MobileNetV2 pr√©-treinado (sem as camadas densas no topo)\n",
    "# O MobileNetV2 √© uma rede neural pr√©-treinada que foi treinada em um grande conjunto de dados chamado ImageNet, que cont√©m milh√µes de imagens de v√°rias categorias diferentes.\n",
    "# weights='imagenet': carregar os pesos pr√©-treinados da vers√£o do MobileNetV2 que foi treinada no conjunto de dados ImageNet\n",
    "# include_top=False: excluindo a camada de classifica√ß√£o final (top) da rede. Essa camada de classifica√ß√£o normalmente consiste em uma camada densa (fully connected)\n",
    "# que produz sa√≠das para cada classe no conjunto de dados original do ImageNet. Excluindo essa camada, voc√™ est√° preparando o modelo para personalizar a camada de classifica√ß√£o para uma nova tarefa.\n",
    "\n",
    "# Defina o tamanho que voc√™ vai usar para as imagens (MobileNetV2 performa bem com 224)\n",
    "image_size_tl = 224\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False,input_shape=(image_size_tl,image_size_tl,3))\n",
    "\n",
    "# Adicione camadas personalizadas no topo para a classifica√ß√£o de c√£es e gatos\n",
    "x = base_model.output\n",
    "\n",
    " # reduzir a dimensionalidade dos dados espaciais antes da camada de sa√≠da,\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# fun√ß√£o de ativa√ß√£o ReLU\n",
    "x = Dense(128, activation='relu')(x) \n",
    "\n",
    "# duas sa√≠das (duas classes, cachorrinhos e gatinhos)\n",
    "predictions = Dense(2, activation='softmax')(x) \n",
    "\n",
    "# Crie o modelo final\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Configurar o layer.trainable**\n",
    "\n",
    "Esse parametro √© importante para manter as camadas j√° treinadas pela MobileNet congelada. \n",
    "Aqui todas as camadas do modelo MobileNet pr√©-treinado s√£o congeladas, e em seguida, camadas personalizadas s√£o adicionadas para realizar a identifica√ß√£o de c√£es e gatos. \n",
    "Durante o treinamento, apenas as camadas personalizadas ter√£o seus pesos ajustados, enquanto as camadas pr√©-treinadas permanecer√£o inalteradas. \n",
    "Para esse efeito acontecer, devemos configurar esse par√¢metro como \"False\".\n",
    "\n",
    "'''\n",
    "\n",
    "# Congelar todas as camadas pr√©-treinadas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ef620",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "E chegou o momento de compilar o modelo!\n",
    "\n",
    "Aqui vamos utilizar a fun√ß√£o de custo adam, otimizando assim a identifica√ß√£o do menor erro poss√≠vel do modelo (loss function).\n",
    "\n",
    "'''\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b0fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/44\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.9949 - loss: 0.0246"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Como pr√≥ximo passo, vamos pegar nossas imagens de c√£es e gatos e \"tunar\" elas com ImageDataGenerator! \n",
    "Essa ferramenta √© muito poderosa para aumentar os dados e pr√©-processar as imagens. \n",
    "Ele permite que voc√™ crie um fluxo de dados de imagens que pode ser usado para treinar modelos de aprendizado profundo.\n",
    "\n",
    "'''\n",
    "\n",
    "# Para evitar problemas de overfitting, usei o ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255, # Normaliza os valores de pixel para o intervalo de 0 a 1.\n",
    "    rotation_range=20, # Aplica rota√ß√µes aleat√≥rias de at√© 20 graus nas imagens.\n",
    "    width_shift_range=0.2, # Realiza deslocamentos aleat√≥rios horizontal e vertical nas imagens.\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2, # corta as bordas\n",
    "    zoom_range=0.2, # aplica zoom nas imagens\n",
    "    horizontal_flip=True, # realiza viragens horizontais aleat√≥rias nas imagens.\n",
    "    fill_mode='nearest' # preenche os pixels que podem ser criados devido a transforma√ß√µes com os valores mais pr√≥ximos.\n",
    ")\n",
    "\n",
    "# Cria a base de treinamento\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    caminho_da_pasta,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Treine o modelo\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Rede foi treinada! Agora vamos validar a performance:\n",
    "\n",
    "'''\n",
    "\n",
    "caminho_da_pasta_teste = config.DATA_PATH_TESTE\n",
    "\n",
    "# chamando dados de teste\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    caminho_da_pasta,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Avalie o modelo no conjunto de teste\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f'Acur√°cia no conjunto de teste: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = r\"C:\\Users\\ricar\\OneDrive\\Cursos\\P√≥s Gradua√ß√£o\\Data Analytics - FIAP\\07 - Fase 5 - Deep Learning and Unstructured Data\\02 - Deep & Reinforcement Learning\\Outros\\imagens_teste\\cat.202.jpg\"\n",
    "guess_animal_transfer_learning(caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcc1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = r\"C:\\Users\\ricar\\OneDrive\\Cursos\\P√≥s Gradua√ß√£o\\Data Analytics - FIAP\\07 - Fase 5 - Deep Learning and Unstructured Data\\02 - Deep & Reinforcement Learning\\Outros\\imagens_teste\\cat.475.jpg\"\n",
    "guess_animal_transfer_learning(caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca1a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = r\"C:\\Users\\ricar\\OneDrive\\Cursos\\P√≥s Gradua√ß√£o\\Data Analytics - FIAP\\07 - Fase 5 - Deep Learning and Unstructured Data\\02 - Deep & Reinforcement Learning\\Outros\\imagens_teste\\dog.30.jpg\"\n",
    "guess_animal_transfer_learning(caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db078eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = r\"C:\\Users\\ricar\\OneDrive\\Cursos\\P√≥s Gradua√ß√£o\\Data Analytics - FIAP\\07 - Fase 5 - Deep Learning and Unstructured Data\\02 - Deep & Reinforcement Learning\\Outros\\imagens_teste\\dog.238.jpg\"\n",
    "guess_animal_transfer_learning(caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4914404",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = r\"C:\\Users\\ricar\\OneDrive\\Cursos\\P√≥s Gradua√ß√£o\\Data Analytics - FIAP\\07 - Fase 5 - Deep Learning and Unstructured Data\\02 - Deep & Reinforcement Learning\\Outros\\imagens_teste\\dog.jpg\"\n",
    "guess_animal_transfer_learning(caminho)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambiente_fase_5_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
