{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d6ca84",
   "metadata": {},
   "source": [
    "#### **Deep & Reinforcement Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580d69f",
   "metadata": {},
   "source": [
    "#### **Observa√ß√µes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbdf99f",
   "metadata": {},
   "source": [
    "##### **Classificando diferentes tipos de semente de ab√≥bora** üéÉüå±\n",
    "\n",
    "As sementes de ab√≥bora s√£o frequentemente consumidas como confeitos em todo o mundo devido √† sua quantidade adequada de prote√≠nas, gorduras, carboidratos e teores minerais. A base de dados **\"SementesAbobora.xlsx\"** possui um estudo foi realizado nos dois tipos de sementes de ab√≥bora mais importantes e de qualidade, **‚Äú√úrg√ºp Sivrisi‚Äù** e **‚Äú√áer√ßevelik‚Äù**, geralmente cultivadas nas regi√µes de √úrg√ºp e Karaca√∂ren na Turquia.\n",
    "\n",
    "Muitas esp√©cies de sementes t√™m semelhan√ßas visuais, o que torna a classifica√ß√£o manual dif√≠cil e sujeita a erros. Redes neurais podem ser treinadas para identificar padr√µes que n√£o s√£o facilmente percept√≠veis pelo olho humano, aumentando a precis√£o da classifica√ß√£o.\n",
    "\n",
    "Imagine que foi proposto para voc√™ o desafio de criar uma **intelig√™ncia para identificar os tipos de sementes para ajudar a equipe de engenheiros e engenheiras Agr√≠colas**. Para trabalhar com a precis√£o dos resultados x complexidade das caracter√≠sticas de sementes, voc√™ optou em utilizar as **redes neurais multilayer perceptron**. Vamos para a aplica√ß√£o?\n",
    "\n",
    "**Features**\n",
    "\n",
    "- Per√≠metro\n",
    "- Maior_Eixo_Comprimento\n",
    "- Comprimento_Eixo_Menor\n",
    "- √Årea_Convexa\n",
    "- Equiv_Di√¢metro\n",
    "- Excentricidade\n",
    "- Solidez\n",
    "- Extens√£o\n",
    "- Redondeza\n",
    "- Proporcao\n",
    "- Compacidade\n",
    "\n",
    "**Target**\n",
    "Classes:\n",
    " ((A)√áer√ßevelik, (B)√úrg√ºp Sivrisi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831837de",
   "metadata": {},
   "source": [
    "##### **Como criar ambientes para evitar conflito:**\n",
    "https://github.com/RicardViana/fiap-data-viz-and-production-models/blob/main/Roteiro%20para%20cria%C3%A7%C3%A3o%20de%20ambiente.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59115f",
   "metadata": {},
   "source": [
    "#### **Conte√∫do - Bases e Notebook da aula**\n",
    "\n",
    "Github:  \n",
    "https://github.com/FIAP/Pos_Tech_DTAT/tree/DeepLearning\n",
    "\n",
    "ou\n",
    "\n",
    "https://github.com/FIAP/Pos_Tech_DTAT/tree/main/Fase%205\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770d68e",
   "metadata": {},
   "source": [
    "#### **Importa√ß√£o de bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar biblioteca completa\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import gdown\n",
    "import config\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Importar algo especifico de uma biblioteca\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics as skm\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import Precision\n",
    "from tqdm.keras import TqdmCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout, Conv2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pathlib import Path\n",
    "from distutils.file_util import copy_file\n",
    "from keras.layers import Input\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import STOPWORDS\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from keras.src.legacy.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, SimpleRNN, Bidirectional, MaxPooling1D, GlobalMaxPool1D, LSTM, GRU\n",
    "from keras.regularizers import L1L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e672ffbc",
   "metadata": {},
   "source": [
    "#### **Fun√ß√µes (def)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70f28a",
   "metadata": {},
   "source": [
    "#### **Aula 1 - Perceptron de m√∫ltiplas camadas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar base de dados\n",
    "\n",
    "link = 'https://github.com/RicardViana/fiap-Deep-Learning-and-unstructured-data/raw/refs/heads/main/SementesAbobora.xlsx'\n",
    "df = pd.read_excel(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86edfac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver os primeiros dados\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa077a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver os ultimos dados\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8510020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver a qtd de linhas e colunas da data frame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como a base de dados possui os dados de classes de forma ordenada, isso pode ser um problema para o aprendizado de m√°quina e dessa forma √© preciso embaralhar os dados com o comando shuffle.\n",
    "\n",
    "'''\n",
    "\n",
    "Se o que voc√™ quer prever √© uma categoria (nome, grupo, \"sim/n√£o\"), voc√™ est√° lidando com Classes.\n",
    "\n",
    "Se o que voc√™ quer prever √© um n√∫mero cont√≠nuo (pre√ßo de uma casa, temperatura, valor do d√≥lar), voc√™ est√° lidando com Regress√£o.\n",
    "\n",
    "'''\n",
    "\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94112b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificar os dados embaralhados\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver o equilibrio da base de dados\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc988d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potando histogramas para analisar a simetria dos dados\n",
    "df.hist(bins=100, figsize=(12, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac05cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificar a correla√ß√£o dos dados\n",
    "correlation_matrix = df.select_dtypes(include='number').corr().round(2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(data=correlation_matrix, annot=True, linewidths=.5, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver a info dos dados\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e179902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando LabelEncoder para transformar/converter r√≥tulos de texto em n√∫meros referente a variavel target\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Sobrescrever a coluna Class\n",
    "df.Class = le.fit_transform(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ad599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar apenas os dados distitos\n",
    "set(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f57fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados \n",
    "X = df[['Area','Per√≠metro', 'Comprimento_Eixo_Menor','Excentricidade','Solidez','Extens√£o','Redondeza', 'Proporcao', 'Compacidade']]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©-processamento dos dados\n",
    "\n",
    "'''\n",
    "\n",
    "Apesar de deep learning n√£o requerer distribui√ß√µes normais, √© comum aplicar t√©cnicas de pr√©-processamento de dados para normalizar ou padronizar as caracter√≠sticas. \n",
    "Isso pode ajudar a acelerar a converg√™ncia do treinamento da rede neural.\n",
    "A converg√™ncia est√° relacionada com o erro, ou seja, o quanto a sua rede aprende a corrigir os erros durante o processamento.\n",
    "\n",
    "'''\n",
    "\n",
    "# Ajustar os dados (Fit)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaler.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f85b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar os dados\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a15a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver os dados de treino\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ae5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver a quantidade de linhas e colunas da base de treino\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver o tipo do dado\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082854d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver a quantidade de linhas e colunas da base de teste\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver o tipo do dado\n",
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61462843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moldando nossas vari√°veis resposta\n",
    "\n",
    "'''\n",
    "\n",
    "A nossas classes est√£o em um formato de estrutura de dados unidimensional (assim como uma coluna) e precisamos moldar para o formato de array -n dimensional(matriz).\n",
    "O comando reshape √© utilizado para reformatar a estrutura de um array multidimensional, como um tensor, que √© a estrutura de dados fundamental usada em deep learning e processamento de dados em redes neurais.\n",
    "\n",
    "'''\n",
    "\n",
    "# Ver o tipo do dado\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea00aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape() molda uma matriz sem alterar os dados da matriz\n",
    "\n",
    "'''\n",
    "\n",
    "O que o .reshape((-1, 1)) faz?\n",
    "\n",
    "Imagine que os dados originais sejam uma lista simples: [0, 1, 0, 1] e para o Python, isso √© um vetor de uma √∫nica dimens√£o (1D). \n",
    "No entanto, bibliotecas como o TensorFlow ou Scikit-Learn geralmente exigem que os dados de entrada tenham duas dimens√µes: uma para as linhas (amostras) e outra para as colunas (caracter√≠sticas).\n",
    "\n",
    "* O n√∫mero 1: Diz ao NumPy que queremos que o resultado final tenha exatamente 1 coluna.\n",
    "* O n√∫mero -1: Esse √© um \"coringa\". Ele diz ao NumPy: \"Calcule automaticamente quantas linhas s√£o necess√°rias para que todos os dados caibam nessa 1 coluna\".\n",
    "\n",
    "O passo a passo da linha inteira\n",
    "\n",
    "O comando abaixo√© uma \"super instru√ß√£o\" que faz tr√™s coisas:\n",
    "\n",
    "1. np.asarray(y_train): Garante que o dado seja um array do NumPy (caso ele venha de uma lista ou de uma coluna do Pandas).\n",
    "2. .astype('float32'): Converte os n√∫meros para o formato de ponto flutuante de 32 bits. Computacionalmente, as GPUs e CPUs processam c√°lculos de Redes Neurais muito mais r√°pido em float32 do que em n√∫meros inteiros ou float64.\n",
    "3. .reshape((-1, 1)): Transforma o vetor de \"deitado\" (1D) para \"em p√©\" (2D), como uma coluna de uma tabela.\n",
    "\n",
    "Por que isso √© necess√°rio?\n",
    "\n",
    "A maioria dos modelos de Deep Learning (como os do Keras/TensorFlow) espera que o seu `y` (o que voc√™ quer prever) tenha o formato (n√∫mero_de_amostras, n√∫mero_de_sa√≠das).\n",
    "\n",
    "Mesmo que voc√™ s√≥ tenha uma sa√≠da (0 ou 1), o modelo espera que essa sa√≠da esteja dentro de uma estrutura de \"coluna\", e n√£o apenas uma lista solta.\n",
    "\n",
    "'''\n",
    "\n",
    "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "y_test = np.asarray(y_test).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8704a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver o tipo do dado ap√≥s o reshape\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver a qtd de linhas e colunas\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semente aleat√≥ria para reprodutibilidade\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Definindo dimens√µes\n",
    "input_dim = X_train.shape[1] \n",
    "output_dim = y_train.shape[1]\n",
    "batch_size = 20\n",
    "\n",
    "# Abrindo a sequ√™ncia do modelo\n",
    "model = models.Sequential()\n",
    "\n",
    "# Definindo a camada de entrada explicitamente\n",
    "model.add(layers.Input(shape=(input_dim,)))\n",
    "\n",
    "# Camada densa inicial (agora sem o par√¢metro input_shape)\n",
    "model.add(layers.Dense(batch_size, activation='relu'))\n",
    "\n",
    "# Camadas ocultas\n",
    "model.add(layers.Dense(12, activation='relu'))\n",
    "model.add(layers.Dense(6, activation='relu'))\n",
    "\n",
    "# Regulariza√ß√£o\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Camada de sa√≠da\n",
    "# Usamos sigmoid porque √© uma classifica√ß√£o bin√°ria (0 ou 1)\n",
    "model.add(layers.Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "# Configura√ß√£o do otimizador e compila√ß√£o\n",
    "learning_rate = 0.001\n",
    "otimizador = Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=otimizador, metrics=['accuracy'])\n",
    "\n",
    "# Visualizar a arquitetura\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar as √©pocas de processamento para a rede treinar e encontrar o menor erro\n",
    "# Configurando as √©pocas de processamento para a converg√™ncia do erro da fun√ß√£o de custo\n",
    "epoch = 100\n",
    "\n",
    "hist = model.fit(X_train\n",
    "                  ,y_train\n",
    "                  ,epochs = epoch\n",
    "                  ,batch_size=batch_size\n",
    "                  ,shuffle=True\n",
    "                  ,validation_data=(X_test, y_test)\n",
    "                  ,verbose=0\n",
    "                  ,callbacks=[TqdmCallback(verbose=0)]\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a acur√°cia\n",
    "acc = '{:.2%}'.format(hist.history['accuracy'][-1])\n",
    "print(f\"O modelo possui uma acur√°cia de {acc} com {epoch} epochs de processamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar o modelo\n",
    "\n",
    "'''\n",
    "\n",
    "√â muito importante comparar a performance do modelo tanto na base de treinamento quanto de valida√ß√£o. \n",
    "Para isso vamos plotar dois gr√°ficos para acompanhar a performance do modelo pelas √©pocas de processamento.\n",
    "\n",
    "'''\n",
    "\n",
    "# Visualizando os resultados de treino\n",
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs_range = range(epoch)\n",
    "\n",
    "# Plot Acur√°cia\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Acur√°cia de Treinamento')\n",
    "plt.plot(epochs_range, val_acc, label='Acur√°cia de Valida√ß√£o')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Acur√°cia de treino e teste')\n",
    "\n",
    "# Plot Erro de treinamento\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Erro de treinamento')\n",
    "plt.plot(epochs_range, val_loss, label='Erro de Valida√ß√£o')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Erro de treinamento vs valida√ß√£o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar o report\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [round(x[0]) for x in y_pred]\n",
    "y_test_class = y_test\n",
    "\n",
    "# classification report\n",
    "class_names = []\n",
    "for i in y.unique():\n",
    "    class_names.append(le.inverse_transform([i])[0])\n",
    "\n",
    "print(classification_report(y_test_class, y_pred_class, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambiente_fase_5_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
